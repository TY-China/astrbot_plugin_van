import os
import json
import re
import random
import asyncio
import time
from datetime import datetime, timedelta
from urllib.parse import quote
from typing import Dict, List, Optional, Union, Any, Tuple
import aiofiles
import aiofiles.os as aos
from pathlib import Path

# å®‰å…¨æ•°å­¦è¡¨è¾¾å¼æ±‚å€¼åº“
try:
    from simpleeval import simple_eval, InvalidExpression
    SIMPLEEVAL_AVAILABLE = True
except ImportError:
    SIMPLEEVAL_AVAILABLE = False

from astrbot.api.event import filter, AstrMessageEvent, MessageEventResult
from astrbot.api.star import Context, Star, register, StarTools
from astrbot.api import logger
from astrbot.api.message_components import *
from astrbot.api import AstrBotConfig


class SafeMathEvaluator:
    """å®‰å…¨çš„æ•°å­¦è¡¨è¾¾å¼æ±‚å€¼å™¨"""
    
    def __init__(self):
        self._cache = {}
        
    def evaluate(self, expr: str) -> Optional[Union[int, float]]:
        """å®‰å…¨åœ°è®¡ç®—æ•°å­¦è¡¨è¾¾å¼"""
        if not expr:
            return None
            
        # ç¼“å­˜ç»“æœ
        if expr in self._cache:
            return self._cache[expr]
        
        # æ¸…ç†è¡¨è¾¾å¼
        expr = expr.strip()
        
        # åªå…è®¸æ•°å­—ã€åŸºæœ¬è¿ç®—ç¬¦å’Œæ‹¬å·
        safe_chars = set('0123456789+-*/.() ')
        if not all(c in safe_chars for c in expr):
            logger.warning(f"è¡¨è¾¾å¼åŒ…å«ä¸å®‰å…¨å­—ç¬¦: {expr}")
            return None
        
        try:
            if SIMPLEEVAL_AVAILABLE:
                # ä½¿ç”¨ simpleeval è¿›è¡Œå®‰å…¨æ±‚å€¼
                result = simple_eval(expr)
            else:
                # å¤‡ç”¨æ–¹æ¡ˆï¼šä»…æ”¯æŒåŸºç¡€å››åˆ™è¿ç®—
                result = self._basic_eval(expr)
            
            # å¤„ç†æ•´æ•°ç»“æœ
            if isinstance(result, float) and result.is_integer():
                result = int(result)
            
            self._cache[expr] = result
            return result
            
        except (InvalidExpression, SyntaxError, ZeroDivisionError, ValueError) as e:
            logger.warning(f"è¡¨è¾¾å¼æ±‚å€¼å¤±è´¥: {expr}, é”™è¯¯: {e}")
            return None
    
    def _basic_eval(self, expr: str) -> Union[int, float]:
        """åŸºç¡€å››åˆ™è¿ç®—æ±‚å€¼ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰"""
        # ç§»é™¤ç©ºæ ¼
        expr = expr.replace(' ', '')
        
        # å¤„ç†æ‹¬å·
        while '(' in expr:
            start = expr.rfind('(')
            end = expr.find(')', start)
            if end == -1:
                break
            sub_expr = expr[start+1:end]
            sub_result = self._basic_eval(sub_expr)
            expr = expr[:start] + str(sub_result) + expr[end+1:]
        
        # å¤„ç†ä¹˜é™¤æ³•
        operators = [('*', lambda a, b: a * b), 
                    ('/', lambda a, b: a / b if b != 0 else 0)]
        
        for op, func in operators:
            while op in expr:
                idx = expr.find(op)
                left = self._extract_left_number(expr, idx)
                right = self._extract_right_number(expr, idx)
                result = func(left, right)
                expr = expr[:idx-len(str(left))] + str(result) + expr[idx+len(str(right))+1:]
        
        # å¤„ç†åŠ å‡æ³•
        result = 0
        current_num = ''
        current_op = '+'
        
        for i, char in enumerate(expr):
            if char in '+-' or i == len(expr) - 1:
                if i == len(expr) - 1:
                    current_num += char
                
                if current_num:
                    num = float(current_num) if '.' in current_num else int(current_num)
                    if current_op == '+':
                        result += num
                    else:
                        result -= num
                
                if char in '+-':
                    current_op = char
                    current_num = ''
            else:
                current_num += char
        
        return result
    
    def _extract_left_number(self, expr: str, idx: int) -> Union[int, float]:
        """å‘å·¦æå–æ•°å­—"""
        i = idx - 1
        num_str = ''
        
        while i >= 0 and expr[i] in '0123456789.':
            num_str = expr[i] + num_str
            i -= 1
        
        if '.' in num_str:
            return float(num_str)
        return int(num_str) if num_str else 0
    
    def _extract_right_number(self, expr: str, idx: int) -> Union[int, float]:
        """å‘å³æå–æ•°å­—"""
        i = idx + 1
        num_str = ''
        
        while i < len(expr) and expr[i] in '0123456789.':
            num_str += expr[i]
            i += 1
        
        if '.' in num_str:
            return float(num_str)
        return int(num_str) if num_str else 0


class CoolingManager:
    """å†·å´æ—¶é—´ç®¡ç†å™¨ï¼ˆé¿å…æ–‡ä»¶ç«æ€æ¡ä»¶ï¼‰"""
    
    def __init__(self, data_dir: Path):
        self.data_dir = data_dir
        self._cooling_data: Dict[str, Dict[Tuple[str, int], float]] = {}
        self._lock = asyncio.Lock()
        self._dirty = False
        self._save_task = None
        
    async def check_cooling(self, user_id: str, lexicon_id: str, item_index: int) -> Union[bool, int]:
        """æ£€æŸ¥å†·å´æ—¶é—´"""
        key = (user_id, item_index)
        cooling_key = f"cooling_{lexicon_id}"
        
        # ç¡®ä¿å†…å­˜ä¸­æœ‰æ•°æ®
        if cooling_key not in self._cooling_data:
            await self._load_cooling_data(lexicon_id)
        
        async with self._lock:
            if cooling_key in self._cooling_data and key in self._cooling_data[cooling_key]:
                expire_time = self._cooling_data[cooling_key][key]
                current_time = time.time()
                
                if current_time >= expire_time:
                    # å†·å´å·²ç»“æŸï¼Œåˆ é™¤è®°å½•
                    del self._cooling_data[cooling_key][key]
                    self._dirty = True
                    return False  # æ²¡æœ‰å†·å´
                else:
                    # è¿”å›å‰©ä½™ç§’æ•°ï¼ˆæ•´æ•°ï¼‰
                    remaining = int(expire_time - current_time)
                    return remaining if remaining > 0 else False
        
        return False  # æ²¡æœ‰å†·å´è®°å½•
    
    async def set_cooling(self, user_id: str, lexicon_id: str, item_index: int, seconds: int):
        """è®¾ç½®å†·å´æ—¶é—´"""
        key = (user_id, item_index)
        cooling_key = f"cooling_{lexicon_id}"
        
        async with self._lock:
            if cooling_key not in self._cooling_data:
                self._cooling_data[cooling_key] = {}
            
            expire_time = time.time() + seconds
            self._cooling_data[cooling_key][key] = expire_time
            self._dirty = True
        
        # è§¦å‘å¼‚æ­¥ä¿å­˜
        await self._schedule_save(lexicon_id)
    
    async def _load_cooling_data(self, lexicon_id: str):
        """ä»æ–‡ä»¶åŠ è½½å†·å´æ•°æ®"""
        cooling_key = f"cooling_{lexicon_id}"
        
        cooling_path = self.data_dir / "cooling" / f"{lexicon_id}.json"
        
        if await aos.path.exists(cooling_path):
            try:
                async with aiofiles.open(cooling_path, 'r', encoding='utf-8') as f:
                    content = await f.read()
                    data = json.loads(content)
                    
                    # è½¬æ¢ä¸ºå†…å­˜æ ¼å¼
                    cooling_data = {}
                    for entry in data:
                        key = (entry["user_id"], entry["item_index"])
                        cooling_data[key] = entry["expire_time"]
                    
                    self._cooling_data[cooling_key] = cooling_data
                    
            except Exception as e:
                logger.error(f"åŠ è½½å†·å´æ•°æ®å¤±è´¥ {lexicon_id}: {e}")
                self._cooling_data[cooling_key] = {}
        else:
            self._cooling_data[cooling_key] = {}
    
    async def _schedule_save(self, lexicon_id: str):
        """è®¡åˆ’ä¿å­˜æ•°æ®ï¼ˆé˜²æŠ–ï¼‰"""
        if self._save_task and not self._save_task.done():
            self._save_task.cancel()
        
        self._save_task = asyncio.create_task(self._save_cooling_data(lexicon_id))
    
    async def _save_cooling_data(self, lexicon_id: str):
        """ä¿å­˜å†·å´æ•°æ®"""
        await asyncio.sleep(1)  # é˜²æŠ–å»¶è¿Ÿ
        
        async with self._lock:
            if not self._dirty:
                return
            
            cooling_key = f"cooling_{lexicon_id}"
            if cooling_key not in self._cooling_data:
                return
            
            # è¿‡æ»¤å·²è¿‡æœŸçš„æ•°æ®
            current_time = time.time()
            valid_data = {
                key: expire_time 
                for key, expire_time in self._cooling_data[cooling_key].items()
                if expire_time > current_time
            }
            self._cooling_data[cooling_key] = valid_data
            
            # è½¬æ¢ä¸ºå¯åºåˆ—åŒ–æ ¼å¼
            save_data = [
                {
                    "user_id": user_id,
                    "item_index": item_index,
                    "expire_time": expire_time
                }
                for (user_id, item_index), expire_time in valid_data.items()
            ]
            
            # ä¿å­˜åˆ°æ–‡ä»¶
            try:
                cooling_dir = self.data_dir / "cooling"
                await aos.makedirs(cooling_dir, exist_ok=True)
                cooling_path = cooling_dir / f"{lexicon_id}.json"
                
                async with aiofiles.open(cooling_path, 'w', encoding='utf-8') as f:
                    await f.write(json.dumps(save_data, indent=2, ensure_ascii=False))
                
                self._dirty = False
                logger.debug(f"å†·å´æ•°æ®å·²ä¿å­˜: {lexicon_id}")
                
            except Exception as e:
                logger.error(f"ä¿å­˜å†·å´æ•°æ®å¤±è´¥ {lexicon_id}: {e}")


class KeywordManager:
    def __init__(self, config: Dict):
        self.config = config
        
        # ä½¿ç”¨ AstrBot çš„æ ‡å‡†æ’ä»¶æ•°æ®ç›®å½•
        # è¿™æ˜¯ç›¸å¯¹äº AstrBot æ ¹ç›®å½•çš„ data/plugin_data/{æ’ä»¶å}/
        self.data_dir = StarTools.get_data_dir()
        logger.info(f"Vanè¯åº“æ•°æ®ç›®å½•: {self.data_dir}")
        
        # æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨ï¼Œä¸å­˜åœ¨åˆ™åˆ›å»º
        lexicon_dir = self.data_dir / "lexicon"
        if not lexicon_dir.exists():
            lexicon_dir.mkdir(parents=True, exist_ok=True)
            logger.info(f"åˆ›å»ºè¯åº“ç›®å½•: {lexicon_dir}")
        
        self.lexicons: Dict[str, Dict] = {}
        self.switch_config: Dict[str, str] = {}
        self.select_config: Dict[str, str] = {}
        self.math_evaluator = SafeMathEvaluator()
        self.cooling_manager = CoolingManager(self.data_dir)
        
    async def initialize(self):
        """å¼‚æ­¥åˆå§‹åŒ–"""
        logger.info("Vanè¯åº“æ’ä»¶æ­£åœ¨åˆå§‹åŒ–...")
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        await self._ensure_directories()
        
        # å¼‚æ­¥åŠ è½½é…ç½®
        await self.load_configs()
        
        logger.info("Vanè¯åº“æ’ä»¶åˆå§‹åŒ–å®Œæˆ")
        
    async def _ensure_directories(self):
        """ç¡®ä¿å¿…è¦çš„ç›®å½•å­˜åœ¨"""
        dirs = [
            self.data_dir / "lexicon",
            self.data_dir / "config",
            self.data_dir / "cooling",
            self.data_dir / "backups",
            self.data_dir / "filecache"
        ]
        
        for dir_path in dirs:
            try:
                await aos.makedirs(dir_path, exist_ok=True)
                logger.debug(f"ç¡®ä¿ç›®å½•å­˜åœ¨: {dir_path}")
            except Exception as e:
                logger.error(f"åˆ›å»ºç›®å½•å¤±è´¥ {dir_path}: {e}")
    
    async def load_configs(self):
        """å¼‚æ­¥åŠ è½½é…ç½®æ–‡ä»¶"""
        # åŠ è½½å¼€å…³é…ç½®
        switch_path = self.data_dir / "switch.txt"
        if await aos.path.exists(switch_path):
            try:
                async with aiofiles.open(switch_path, 'r', encoding='utf-8') as f:
                    content = await f.read()
                    for line in content.splitlines():
                        line = line.strip()
                        if line and '=' in line:
                            k, v = line.split('=', 1)
                            self.switch_config[k.strip()] = v.strip()
                logger.info(f"åŠ è½½å¼€å…³é…ç½®: {len(self.switch_config)} æ¡")
            except Exception as e:
                logger.error(f"åŠ è½½å¼€å…³é…ç½®å¤±è´¥: {e}")
        
        # åŠ è½½é€‰æ‹©é…ç½®
        select_path = self.data_dir / "select.txt"
        if await aos.path.exists(select_path):
            try:
                async with aiofiles.open(select_path, 'r', encoding='utf-8') as f:
                    content = await f.read()
                    for line in content.splitlines():
                        line = line.strip()
                        if line and '=' in line:
                            k, v = line.split('=', 1)
                            self.select_config[k.strip()] = v.strip()
                logger.info(f"åŠ è½½é€‰æ‹©é…ç½®: {len(self.select_config)} æ¡")
            except Exception as e:
                logger.error(f"åŠ è½½é€‰æ‹©é…ç½®å¤±è´¥: {e}")
    
    def get_lexicon_id(self, group_id: str, user_id: str = "") -> str:
        """
        è·å–è¯åº“ID
        é€»è¾‘ï¼šä¼˜å…ˆä½¿ç”¨ç”¨æˆ·é€‰æ‹©çš„è¯åº“ï¼Œç„¶åä½¿ç”¨ç¾¤ç»„å¼€å…³é…ç½®çš„è¯åº“ï¼Œæœ€åä½¿ç”¨é»˜è®¤è¯åº“
        """
        # 1. ç”¨æˆ·é€‰æ‹©çš„è¯åº“ï¼ˆé€šè¿‡select.txté…ç½®ï¼‰
        if user_id and user_id in self.select_config:
            lexicon_id = self.select_config[user_id]
            logger.debug(f"ä½¿ç”¨ç”¨æˆ·é€‰æ‹©è¯åº“: user={user_id}, lexicon={lexicon_id}")
            return lexicon_id
        
        # 2. ç¾¤ç»„å¼€å…³é…ç½®çš„è¯åº“ï¼ˆé€šè¿‡switch.txté…ç½®ï¼‰
        if group_id and group_id in self.switch_config:
            lexicon_id = self.switch_config[group_id]
            if lexicon_id:  # éç©ºå­—ç¬¦ä¸²
                logger.debug(f"ä½¿ç”¨ç¾¤ç»„å¼€å…³è¯åº“: group={group_id}, lexicon={lexicon_id}")
                return lexicon_id
        
        # 3. é»˜è®¤è¯åº“ï¼ˆç§èŠä½¿ç”¨ç”¨æˆ·IDï¼Œç¾¤èŠä½¿ç”¨ç¾¤ç»„IDï¼‰
        if not group_id or group_id == "":
            # ç§èŠï¼šä½¿ç”¨ç”¨æˆ·IDä½œä¸ºè¯åº“ID
            lexicon_id = f"private_{user_id}"
        else:
            # ç¾¤èŠï¼šä½¿ç”¨ç¾¤ç»„IDä½œä¸ºè¯åº“ID
            lexicon_id = group_id
        
        logger.debug(f"ä½¿ç”¨é»˜è®¤è¯åº“: group={group_id}, user={user_id}, lexicon={lexicon_id}")
        return lexicon_id
    
    async def get_lexicon(self, group_id: str, user_id: str = "") -> Dict:
        """è·å–è¯åº“æ•°æ®"""
        lexicon_id = self.get_lexicon_id(group_id, user_id)
        lexicon_path = self.data_dir / "lexicon" / f"{lexicon_id}.json"

        # å†…å­˜ç¼“å­˜
        if lexicon_id in self.lexicons:
            return self.lexicons[lexicon_id]

        try:
            if await aos.path.exists(lexicon_path):
                logger.info(f"ä»æ–‡ä»¶åŠ è½½è¯åº“: {lexicon_path}")
                async with aiofiles.open(lexicon_path, 'r', encoding='utf-8') as f:
                    content = await f.read()
                    data = json.loads(content)
                    self.lexicons[lexicon_id] = data
                    
                    # è®°å½•è¯åº“ä¿¡æ¯
                    word_count = len(data.get("work", []))
                    logger.info(f"è¯åº“ {lexicon_id} åŠ è½½æˆåŠŸï¼ŒåŒ…å« {word_count} ä¸ªè¯æ¡")
                    return data
            else:
                logger.info(f"è¯åº“æ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ›å»ºç©ºè¯åº“: {lexicon_path}")
                # åˆ›å»ºç©ºè¯åº“æ–‡ä»¶
                empty_data = {"work": []}
                async with aiofiles.open(lexicon_path, 'w', encoding='utf-8') as f:
                    await f.write(json.dumps(empty_data, indent=4, ensure_ascii=False))
                
                self.lexicons[lexicon_id] = empty_data
                return empty_data
                
        except Exception as e:
            logger.error(f"åŠ è½½è¯åº“å¤±è´¥ {lexicon_id}: {e}")
            # è¿”å›ç©ºè¯åº“
            empty_data = {"work": []}
            self.lexicons[lexicon_id] = empty_data
            return empty_data

    async def save_lexicon(self, lexicon_id: str, data: Dict):
        """ä¿å­˜è¯åº“"""
        lexicon_path = self.data_dir / "lexicon" / f"{lexicon_id}.json"
        self.lexicons[lexicon_id] = data

        try:
            async with aiofiles.open(lexicon_path, 'w', encoding='utf-8') as f:
                await f.write(json.dumps(data, indent=4, ensure_ascii=False))
            logger.info(f"è¯åº“ä¿å­˜æˆåŠŸ: {lexicon_id}, è¯æ¡æ•°: {len(data.get('work', []))}")
        except Exception as e:
            logger.error(f"ä¿å­˜è¯åº“å¤±è´¥ {lexicon_id}: {e}")

    async def search_keyword(self, text: str, group_id: str, user_id: str, is_admin: bool = False) -> Optional[Dict]:
        """æœç´¢åŒ¹é…çš„å…³é”®è¯"""
        lexicon = await self.get_lexicon(group_id, user_id)
        current_lexicon_id = self.get_lexicon_id(group_id, user_id)

        # æœç´¢é¡ºåºï¼šå½“å‰è¯åº“ -> é»˜è®¤è¯åº“ï¼ˆå¦‚æœæ˜¯ç§èŠåˆ™è·³è¿‡ï¼‰
        lexicon_ids = [current_lexicon_id]
        
        # å¦‚æœæ˜¯ç¾¤èŠï¼Œå¹¶ä¸”å½“å‰ä¸æ˜¯ä½¿ç”¨çš„ç¾¤ç»„é»˜è®¤è¯åº“ï¼Œåˆ™ä¹Ÿæœç´¢ç¾¤ç»„é»˜è®¤è¯åº“
        if group_id and current_lexicon_id != group_id:
            lexicon_ids.append(group_id)
        
        # å¦‚æœæ˜¯ç§èŠï¼Œå¹¶ä¸”å½“å‰ä¸æ˜¯ä½¿ç”¨çš„ç”¨æˆ·é»˜è®¤è¯åº“ï¼Œåˆ™ä¹Ÿæœç´¢ç”¨æˆ·é»˜è®¤è¯åº“
        if not group_id and current_lexicon_id != f"private_{user_id}":
            lexicon_ids.append(f"private_{user_id}")

        logger.debug(f"æœç´¢å…³é”®è¯: text='{text}', group={group_id}, user={user_id}")
        logger.debug(f"æœç´¢è¯åº“åˆ—è¡¨: {lexicon_ids}")

        for lid in lexicon_ids:
            lex_data = await self.get_lexicon(lid, "")
            logger.debug(f"æ£€æŸ¥è¯åº“ {lid}: è¯æ¡æ•°={len(lex_data.get('work', []))}")
            
            for idx, item in enumerate(lex_data.get("work", [])):
                for key, value in item.items():
                    # æ£€æŸ¥ç®¡ç†å‘˜æ¨¡å¼
                    if value.get("s") == 10 and not is_admin:
                        logger.debug(f"è·³è¿‡ç®¡ç†å‘˜æ¨¡å¼è¯æ¡: {key}")
                        continue
                    
                    # æ£€æŸ¥é€šé…ç¬¦åŒ¹é…
                    if "[n." in key:
                        match_result = self.match_wildcard(key, text)
                        if match_result:
                            logger.info(f"é€šé…ç¬¦åŒ¹é…æˆåŠŸ: è¯åº“={lid}, key='{key}', text='{text}'")
                            return {
                                "type": "wildcard",
                                "response": random.choice(value["r"]),
                                "matches": match_result,
                                "lexicon_id": lid,
                                "item_index": idx,
                                "keyword": key
                            }
                    
                    # ç²¾ç¡®åŒ¹é…
                    if value.get("s") == 1 and key == text:
                        logger.info(f"ç²¾ç¡®åŒ¹é…æˆåŠŸ: è¯åº“={lid}, key='{key}', text='{text}'")
                        return {
                            "type": "exact",
                            "response": random.choice(value["r"]),
                            "lexicon_id": lid,
                            "item_index": idx,
                            "keyword": key
                        }
                    
                    # æ¨¡ç³ŠåŒ¹é…
                    if value.get("s") == 0 and key in text:
                        logger.info(f"æ¨¡ç³ŠåŒ¹é…æˆåŠŸ: è¯åº“={lid}, key='{key}', text='{text}'")
                        return {
                            "type": "fuzzy",
                            "response": random.choice(value["r"]),
                            "lexicon_id": lid,
                            "item_index": idx,
                            "keyword": key
                        }
        
        logger.debug(f"æœªæ‰¾åˆ°åŒ¹é…çš„å…³é”®è¯: '{text}'")
        return None

    def match_wildcard(self, pattern: str, text: str) -> Optional[List[str]]:
        """é€šé…ç¬¦åŒ¹é…"""
        # è½¬ä¹‰ç‰¹æ®Šå­—ç¬¦
        safe_pattern = re.escape(pattern)
        # å°† [n.x] æ›¿æ¢ä¸º (.+?)
        safe_pattern = re.sub(r'\\\[n\\.(\d+)\\\]', r'(.+?)', safe_pattern)

        try:
            match = re.match(f"^{safe_pattern}$", text)
            if match:
                groups = match.groups()
                result = ["", "", "", "", "", ""]  # n.0 åˆ° n.5
                
                # è·å–æ‰€æœ‰å ä½ç¬¦ç´¢å¼•
                placeholders = re.findall(r'\[n\.(\d+)\]', pattern)
                for idx, ph in enumerate(placeholders):
                    ph_idx = int(ph)
                    if ph_idx < len(result) and idx < len(groups):
                        result[ph_idx] = groups[idx]
                return result
        except re.error as e:
            logger.error(f"æ­£åˆ™åŒ¹é…é”™è¯¯: {e}")

        return None

    async def process_response(self, response: str, matches: Optional[List[str]], event: AstrMessageEvent) -> Optional[List[BaseMessageComponent]]:
        """å¤„ç†å“åº”æ–‡æœ¬ï¼Œè¿”å›æ¶ˆæ¯ç»„ä»¶åˆ—è¡¨"""
        if isinstance(response, dict):
            base_response = response["response"]
            matches = response.get("matches", [])
        else:
            base_response = response
            matches = matches or []

        text = base_response

        # æ›¿æ¢é€šé…ç¬¦
        if matches:
            for i in range(1, 6):
                if i < len(matches) and matches[i]:
                    text = text.replace(f"[n.{i}]", matches[i])
                    # æ¸…ç†é€šé…ç¬¦å†…å®¹ï¼Œåªä¿ç•™å®‰å…¨å­—ç¬¦
                    clean_match = re.search(r'[\d\w/.:?=&-]+', matches[i])
                    if clean_match:
                        text = text.replace(f"[n.{i}.t]", clean_match.group())

        # è·å–å‘é€è€…ä¿¡æ¯ - ä½¿ç”¨AstrBotæ ‡å‡†API
        group_id = event.get_group_id() or ""
        sender_id = str(event.get_sender_id())
        
        # ä½¿ç”¨ event.get_sender_name() è·å–å‘é€è€…åç§°
        sender_name = event.get_sender_name() or sender_id
        
        # æ›¿æ¢ç”¨æˆ·å˜é‡
        text = text.replace("[qq]", sender_id)
        text = text.replace("[group]", str(group_id))
        text = text.replace("[name]", sender_name)
        text = text.replace("[card]", sender_name)
        
        # è·å–æœºå™¨äººID
        try:
            bot_id = event.self_id  # é€šç”¨å±æ€§
            text = text.replace("[ai]", str(bot_id))
        except AttributeError:
            # å¤‡é€‰æ–¹æ³•
            try:
                bot_id = event.bot_id if hasattr(event, 'bot_id') else "unknown"
                text = text.replace("[ai]", str(bot_id))
            except:
                text = text.replace("[ai]", "unknown")

        # æ¶ˆæ¯ID - ä½¿ç”¨ message_obj å±æ€§
        try:
            message_id = str(event.message_obj.message_id)
            text = text.replace("[id]", message_id)
            text = text.replace("[æ¶ˆæ¯id]", message_id)
        except AttributeError:
            logger.warning("æ— æ³•è·å–æ¶ˆæ¯IDï¼Œè·³è¿‡ [id] å’Œ [æ¶ˆæ¯id] å˜é‡æ›¿æ¢")

        # å¤„ç†éšæœºæ•°
        while True:
            match = re.search(r'\((\d+)-(\d+)\)', text)
            if not match:
                break
            min_val = int(match.group(1))
            max_val = int(match.group(2))
            rand_num = random.randint(min_val, max_val)
            text = text.replace(match.group(0), str(rand_num), 1)

        # å¤„ç†æ—¶é—´å˜é‡
        now = datetime.now()
        time_replacements = {
            r'\(Y\)': str(now.year),
            r'\(M\)': str(now.month),
            r'\(D\)': str(now.day),
            r'\(h\)': str(now.hour),
            r'\(m\)': str(now.minute),
            r'\(s\)': str(now.second)
        }

        for pattern, replacement in time_replacements.items():
            text = re.sub(pattern, replacement, text)

        # å®‰å…¨å¤„ç†è®¡ç®—è¡¨è¾¾å¼
        while True:
            match = re.search(r'\(\+([^\)]+)\)', text)
            if not match:
                break
            expr = match.group(1)
            try:
                # ä½¿ç”¨å®‰å…¨æ±‚å€¼å™¨
                result = self.math_evaluator.evaluate(expr)
                if result is not None:
                    text = text.replace(match.group(0), str(result), 1)
                else:
                    # æ±‚å€¼å¤±è´¥ï¼Œä¿ç•™åŸè¡¨è¾¾å¼
                    break
            except Exception as e:
                logger.error(f"æ•°å­¦è¡¨è¾¾å¼æ±‚å€¼å¼‚å¸¸: {expr}, é”™è¯¯: {e}")
                break

        # å¤„ç†æ¡ä»¶åˆ¤æ–­
        match_compare = re.search(r'\{(.*?)([><=])(.*?)\}', text)
        if match_compare:
            a = match_compare.group(1)
            op = match_compare.group(2)
            b = match_compare.group(3)
            result = False

            try:
                a_val = int(a) if a.isdigit() else a
                b_val = int(b) if b.isdigit() else b

                if op == '>':
                    result = a_val > b_val
                elif op == '<':
                    result = a_val < b_val
                elif op == '=':
                    result = str(a_val) == str(b_val)
            except ValueError:
                result = False

            if result:
                text = re.sub(r'\{.*?[><=].*?\}', '', text)
            else:
                return None

        # è§£æç‰¹æ®Šå‘½ä»¤
        return await self.parse_special_commands(text, event)

    async def parse_special_commands(self, text: str, event: AstrMessageEvent) -> List[BaseMessageComponent]:
        """è§£æç‰¹æ®Šå‘½ä»¤ï¼Œè¿”å›æ¶ˆæ¯ç»„ä»¶åˆ—è¡¨"""
        chain = []

        parts = re.split(r'(\[.*?\])', text)

        for part in parts:
            if not part.strip():
                continue

            if part.startswith('[') and part.endswith(']'):
                cmd = part[1:-1]
                cmd_parts = cmd.split('.')

                if len(cmd_parts) >= 2:
                    cmd_type = cmd_parts[0].lower()

                    if cmd_type in ["image", "å›¾ç‰‡"]:
                        url = '.'.join(cmd_parts[1:])
                        if url.startswith(('http://', 'https://')):
                            try:
                                chain.append(Image.fromURL(url))
                            except Exception as e:
                                logger.error(f"åŠ è½½å›¾ç‰‡å¤±è´¥: {url}, é”™è¯¯: {e}")
                                chain.append(Plain(f"[å›¾ç‰‡åŠ è½½å¤±è´¥: {url}]"))
                        else:
                            try:
                                # ç›¸å¯¹äºæ’ä»¶æ•°æ®ç›®å½•çš„æ–‡ä»¶
                                file_path = self.data_dir / "filecache" / url
                                chain.append(Image.fromFileSystem(str(file_path)))
                            except Exception as e:
                                logger.error(f"åŠ è½½æœ¬åœ°å›¾ç‰‡å¤±è´¥: {url}, é”™è¯¯: {e}")
                                chain.append(Plain(f"[æœ¬åœ°å›¾ç‰‡åŠ è½½å¤±è´¥: {url}]"))

                    elif cmd_type in ["at", "è‰¾ç‰¹"]:
                        if len(cmd_parts) >= 2 and cmd_parts[1]:
                            qq = cmd_parts[1]
                            chain.append(At(qq=qq))
                        else:
                            chain.append(At(qq=str(event.get_sender_id())))

                    elif cmd_type in ["face", "è¡¨æƒ…"]:
                        if len(cmd_parts) >= 2 and cmd_parts[1]:
                            face_id = cmd_parts[1]
                            chain.append(Face(id=face_id))

                    elif cmd_type in ["reply", "å›å¤"]:
                        if len(cmd_parts) >= 2 and cmd_parts[1]:
                            msg_id = cmd_parts[1]
                            chain.append(Reply(message_id=msg_id))
                        else:
                            # ä½¿ç”¨ event.message_obj è·å–æ¶ˆæ¯ID
                            try:
                                msg_id = event.message_obj.message_id
                                chain.append(Reply(message_id=msg_id))
                            except AttributeError:
                                logger.warning("æ— æ³•è·å–æ¶ˆæ¯IDï¼Œè·³è¿‡å›å¤æ¶ˆæ¯æ®µ")
                                chain.append(Plain("[å›å¤]"))

                    elif cmd_type in ["record", "è¯­éŸ³"]:
                        url = '.'.join(cmd_parts[1:])
                        try:
                            chain.append(Record(file=url))
                        except Exception as e:
                            logger.error(f"åŠ è½½è¯­éŸ³å¤±è´¥: {url}, é”™è¯¯: {e}")
                            chain.append(Plain(f"[è¯­éŸ³åŠ è½½å¤±è´¥: {url}]"))

                    elif cmd_type == "poke":
                        if len(cmd_parts) >= 3:
                            target_id = cmd_parts[1]
                            chain.append(Poke(qq=target_id))

                    else:
                        chain.append(Plain(part))
            else:
                chain.append(Plain(part))

        return chain

    # ç®¡ç†åŠŸèƒ½
    async def add_keyword(self, group_id: str, user_id: str, keyword: str, response: str, mode: int = 0) -> Tuple[bool, str]:
        """æ·»åŠ å…³é”®è¯"""
        lexicon_id = self.get_lexicon_id(group_id, user_id)
        lexicon = await self.get_lexicon(lexicon_id, "")

        # æ£€æŸ¥è¯æ¡æ˜¯å¦å·²å­˜åœ¨
        for item in lexicon["work"]:
            if keyword in item:
                return False, "è¯æ¡å·²å­˜åœ¨"

        # å®¹é”™å¤„ç†
        if self.config.get("mistake_turn_type", False):
            keyword = (keyword.replace('ã€', '[').replace('ã€‘', ']')
                      .replace('ï¼ˆ', '(').replace('ï¼‰', ')')
                      .replace('ï½›', '{').replace('ï½', '}').replace('ï¼š', ':'))

        new_item = {keyword: {"r": [response], "s": mode}}
        lexicon["work"].append(new_item)

        await self.save_lexicon(lexicon_id, lexicon)
        return True, "æ·»åŠ æˆåŠŸ"

    async def remove_keyword(self, group_id: str, user_id: str, keyword: str) -> Tuple[bool, str]:
        """åˆ é™¤å…³é”®è¯"""
        lexicon_id = self.get_lexicon_id(group_id, user_id)
        lexicon = await self.get_lexicon(lexicon_id, "")

        new_work = [item for item in lexicon["work"] if keyword not in item]

        if len(new_work) == len(lexicon["work"]):
            return False, "è¯æ¡ä¸å­˜åœ¨"

        lexicon["work"] = new_work
        await self.save_lexicon(lexicon_id, lexicon)
        return True, "åˆ é™¤æˆåŠŸ"

    async def add_response(self, group_id: str, user_id: str, keyword: str, response: str) -> Tuple[bool, str]:
        """ä¸ºå…³é”®è¯æ·»åŠ å›å¤é€‰é¡¹"""
        lexicon_id = self.get_lexicon_id(group_id, user_id)
        lexicon = await self.get_lexicon(lexicon_id, "")

        for item in lexicon["work"]:
            if keyword in item:
                item[keyword]["r"].append(response)
                await self.save_lexicon(lexicon_id, lexicon)
                return True, "æ·»åŠ æˆåŠŸ"

        return False, "è¯æ¡ä¸å­˜åœ¨"

    async def remove_response(self, group_id: str, user_id: str, keyword: str, response: str) -> Tuple[bool, str]:
        """åˆ é™¤å…³é”®è¯çš„æŸä¸ªå›å¤é€‰é¡¹"""
        lexicon_id = self.get_lexicon_id(group_id, user_id)
        lexicon = await self.get_lexicon(lexicon_id, "")

        for item in lexicon["work"]:
            if keyword in item and response in item[keyword]["r"]:
                item[keyword]["r"].remove(response)
                if not item[keyword]["r"]:
                    lexicon["work"].remove(item)
                await self.save_lexicon(lexicon_id, lexicon)
                return True, "åˆ é™¤æˆåŠŸ"

        return False, "è¯æ¡æˆ–å›å¤ä¸å­˜åœ¨"

    async def list_keywords(self, group_id: str, user_id: str, keyword_filter: str = "") -> List[str]:
        """åˆ—å‡ºå…³é”®è¯"""
        lexicon_id = self.get_lexicon_id(group_id, user_id)
        lexicon = await self.get_lexicon(lexicon_id, "")

        results = []
        for idx, item in enumerate(lexicon["work"]):
            for key, value in item.items():
                if not keyword_filter or keyword_filter in key:
                    mode_str = {
                        0: "æ¨¡ç³Š",
                        1: "ç²¾å‡†",
                        10: "ç®¡ç†"
                    }.get(value["s"], "æœªçŸ¥")
                    results.append(f"{idx+1}. {key} ({mode_str}) - {len(value['r'])}ä¸ªå›å¤")

        return results

    async def get_keyword_detail(self, group_id: str, user_id: str, keyword_id: int) -> Optional[Dict]:
        """è·å–å…³é”®è¯è¯¦æƒ…"""
        lexicon_id = self.get_lexicon_id(group_id, user_id)
        lexicon = await self.get_lexicon(lexicon_id, "")

        if 1 <= keyword_id <= len(lexicon["work"]):
            item = lexicon["work"][keyword_id-1]
            key = list(item.keys())[0]
            return {
                "keyword": key,
                "responses": item[key]["r"],
                "mode": item[key]["s"]
            }

        return None


@register("keyword_astrbot", "Van", "Vanè¯åº“ç³»ç»Ÿ", "1.0.0")
class KeywordPlugin(Star):
    def __init__(self, context: Context, config: AstrBotConfig):
        super().__init__(context)
        self.config = config
        self.keyword_manager = None
        self.admin_ids = set()
        self.ignore_groups = set()
        self.ignore_users = set()

    async def initialize(self):
        logger.info("Vanè¯åº“æ’ä»¶æ­£åœ¨åˆå§‹åŒ–...")

        self.parse_config()

        self.keyword_manager = KeywordManager(dict(self.config))
        await self.keyword_manager.initialize()

        logger.info("Vanè¯åº“æ’ä»¶åˆå§‹åŒ–å®Œæˆ")

    def parse_config(self):
        """è§£æé…ç½®"""
        admin_text = self.config.get("admin_ids", "")
        self.admin_ids = set(line.strip() for line in admin_text.split('\n') if line.strip())

        ignore_groups_text = self.config.get("ignore_group_ids", "")
        self.ignore_groups = set(line.strip() for line in ignore_groups_text.split('\n') if line.strip())

        ignore_users_text = self.config.get("ignore_user_ids", "")
        self.ignore_users = set(line.strip() for line in ignore_users_text.split('\n') if line.strip())
        
        logger.info(f"ç®¡ç†å‘˜åˆ—è¡¨: {self.admin_ids}")
        logger.info(f"å¿½ç•¥ç¾¤ç»„: {self.ignore_groups}")
        logger.info(f"å¿½ç•¥ç”¨æˆ·: {self.ignore_users}")

    def is_admin(self, user_id: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºç®¡ç†å‘˜"""
        return user_id in self.admin_ids

    def should_ignore(self, group_id: str, user_id: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦åº”è¯¥å¿½ç•¥"""
        if group_id and group_id in self.ignore_groups:
            logger.debug(f"å¿½ç•¥ç¾¤ç»„æ¶ˆæ¯: group={group_id}")
            return True
        if user_id in self.ignore_users:
            logger.debug(f"å¿½ç•¥ç”¨æˆ·æ¶ˆæ¯: user={user_id}")
            return True
        return False

    @filter.event_message_type(filter.EventMessageType.GROUP_MESSAGE)
    async def handle_group_message(self, event: AstrMessageEvent):
        """å¤„ç†ç¾¤èŠæ¶ˆæ¯"""
        # è¿‡æ»¤è‡ªèº«æ¶ˆæ¯
        try:
            bot_id = event.self_id  # é€šç”¨å±æ€§
            sender_id = event.get_sender_id()
            if str(sender_id) == str(bot_id):
                logger.debug(f"å¿½ç•¥è‡ªèº«æ¶ˆæ¯: sender_id={sender_id}, bot_id={bot_id}")
                return
        except AttributeError:
            # å¦‚æœ event æ²¡æœ‰ self_id å±æ€§ï¼Œå°è¯•å…¶ä»–æ–¹æ³•
            try:
                bot_id = event.bot_id if hasattr(event, 'bot_id') else None
                sender_id = event.get_sender_id()
                if bot_id and str(sender_id) == str(bot_id):
                    logger.debug(f"å¿½ç•¥è‡ªèº«æ¶ˆæ¯ (å¤‡ç”¨æ–¹æ³•): sender_id={sender_id}, bot_id={bot_id}")
                    return
            except:
                pass  # å¦‚æœæ— æ³•è·å–ï¼Œç»§ç»­å¤„ç†
        
        group_id = str(event.get_group_id() or "")
        user_id = str(event.get_sender_id())

        logger.debug(f"æ”¶åˆ°ç¾¤èŠæ¶ˆæ¯: group={group_id}, user={user_id}")

        if self.should_ignore(group_id, user_id):
            return

        message_text = event.message_str.strip()

        # å…ˆæ£€æŸ¥æ˜¯å¦ä¸ºç®¡ç†å‘˜æŒ‡ä»¤
        if self.is_admin(user_id):
            handled = await self.handle_admin_command(message_text, event)
            if handled:
                return

        # å…³é”®è¯åŒ¹é…
        result = await self.keyword_manager.search_keyword(
            message_text,
            group_id,
            user_id,
            self.is_admin(user_id)
        )

        if result:
            logger.info(f"å…³é”®è¯åŒ¹é…æˆåŠŸ: {result.get('keyword')}")
            
            # æ£€æŸ¥å†·å´æ—¶é—´
            lexicon_id = result.get("lexicon_id", "")
            item_index = result.get("item_index", 0)
            
            cooling = await self.keyword_manager.cooling_manager.check_cooling(
                user_id, lexicon_id, item_index
            )

            # cooling ä¸º False è¡¨ç¤ºæ²¡æœ‰å†·å´ï¼Œä¸º int è¡¨ç¤ºå‰©ä½™ç§’æ•°
            if isinstance(cooling, int) and cooling > 0:
                cooling_msg = f"å†·å´ä¸­ï¼Œè¯·ç­‰å¾… {cooling} ç§’"
                logger.debug(f"è§¦å‘å†·å´: {cooling_msg}")
                yield event.plain_result(cooling_msg)
                return

            # å¤„ç†å“åº”
            response_chain = await self.keyword_manager.process_response(result, None, event)

            if response_chain:
                logger.debug(f"å‘é€å“åº”æ¶ˆæ¯ï¼Œç»„ä»¶æ•°: {len(response_chain)}")
                yield event.chain_result(response_chain)
                
                # å¤„ç†å†·å´æ—¶é—´è®¾ç½®
                cooling_match = re.search(r'\((\d+)~\)', result.get("response", ""))
                if cooling_match:
                    seconds = int(cooling_match.group(1))
                    if seconds == 0:
                        tomorrow = datetime.now() + timedelta(days=1)
                        tomorrow_midnight = tomorrow.replace(hour=0, minute=0, second=0, microsecond=0)
                        seconds = int(tomorrow_midnight.timestamp() - datetime.now().timestamp())
                    
                    await self.keyword_manager.cooling_manager.set_cooling(
                        user_id, lexicon_id, item_index, seconds
                    )
                    logger.debug(f"è®¾ç½®å†·å´æ—¶é—´: {seconds}ç§’")

    @filter.event_message_type(filter.EventMessageType.PRIVATE_MESSAGE)
    async def handle_private_message(self, event: AstrMessageEvent):
        """å¤„ç†ç§èŠæ¶ˆæ¯"""
        # è¿‡æ»¤è‡ªèº«æ¶ˆæ¯
        try:
            bot_id = event.self_id  # é€šç”¨å±æ€§
            sender_id = event.get_sender_id()
            if str(sender_id) == str(bot_id):
                logger.debug(f"å¿½ç•¥è‡ªèº«æ¶ˆæ¯: sender_id={sender_id}, bot_id={bot_id}")
                return
        except AttributeError:
            # å¦‚æœ event æ²¡æœ‰ self_id å±æ€§ï¼Œå°è¯•å…¶ä»–æ–¹æ³•
            try:
                bot_id = event.bot_id if hasattr(event, 'bot_id') else None
                sender_id = event.get_sender_id()
                if bot_id and str(sender_id) == str(bot_id):
                    logger.debug(f"å¿½ç•¥è‡ªèº«æ¶ˆæ¯ (å¤‡ç”¨æ–¹æ³•): sender_id={sender_id}, bot_id={bot_id}")
                    return
            except:
                pass  # å¦‚æœæ— æ³•è·å–ï¼Œç»§ç»­å¤„ç†
        
        user_id = str(event.get_sender_id())
        logger.debug(f"æ”¶åˆ°ç§èŠæ¶ˆæ¯: user={user_id}")

        if self.should_ignore("", user_id):
            return

        message_text = event.message_str.strip()

        # ç§èŠä¹Ÿæ”¯æŒç®¡ç†å‘˜æŒ‡ä»¤
        if self.is_admin(user_id):
            handled = await self.handle_admin_command(message_text, event)
            if handled:
                return

        # ç§èŠå…³é”®è¯åŒ¹é…
        result = await self.keyword_manager.search_keyword(
            message_text,
            "",  # ç§èŠæ²¡æœ‰ç¾¤ç»„ID
            user_id,
            self.is_admin(user_id)
        )

        if result:
            logger.info(f"ç§èŠå…³é”®è¯åŒ¹é…æˆåŠŸ: {result.get('keyword')}")
            
            # æ£€æŸ¥å†·å´æ—¶é—´
            lexicon_id = result.get("lexicon_id", "")
            item_index = result.get("item_index", 0)
            
            cooling = await self.keyword_manager.cooling_manager.check_cooling(
                user_id, lexicon_id, item_index
            )

            # cooling ä¸º False è¡¨ç¤ºæ²¡æœ‰å†·å´ï¼Œä¸º int è¡¨ç¤ºå‰©ä½™ç§’æ•°
            if isinstance(cooling, int) and cooling > 0:
                cooling_msg = f"å†·å´ä¸­ï¼Œè¯·ç­‰å¾… {cooling} ç§’"
                logger.debug(f"ç§èŠè§¦å‘å†·å´: {cooling_msg}")
                yield event.plain_result(cooling_msg)
                return

            # å¤„ç†å“åº”
            response_chain = await self.keyword_manager.process_response(result, None, event)

            if response_chain:
                logger.debug(f"å‘é€ç§èŠå“åº”æ¶ˆæ¯ï¼Œç»„ä»¶æ•°: {len(response_chain)}")
                yield event.chain_result(response_chain)
                
                # å¤„ç†å†·å´æ—¶é—´è®¾ç½®
                cooling_match = re.search(r'\((\d+)~\)', result.get("response", ""))
                if cooling_match:
                    seconds = int(cooling_match.group(1))
                    if seconds == 0:
                        tomorrow = datetime.now() + timedelta(days=1)
                        tomorrow_midnight = tomorrow.replace(hour=0, minute=0, second=0, microsecond=0)
                        seconds = int(tomorrow_midnight.timestamp() - datetime.now().timestamp())
                
                    await self.keyword_manager.cooling_manager.set_cooling(
                        user_id, lexicon_id, item_index, seconds
                    )
                    logger.debug(f"è®¾ç½®ç§èŠå†·å´æ—¶é—´: {seconds}ç§’")

    async def handle_admin_command(self, message: str, event: AstrMessageEvent) -> bool:
        """å¤„ç†ç®¡ç†å‘˜æŒ‡ä»¤ï¼Œè¿”å›æ˜¯å¦å¤„ç†æˆåŠŸ"""
        group_id = str(event.get_group_id() or "")
        user_id = str(event.get_sender_id())

        logger.debug(f"æ£€æŸ¥ç®¡ç†å‘˜æŒ‡ä»¤: {message}")

        # ç²¾å‡†é—®ç­”
        if message.startswith("ç²¾å‡†é—®ç­” "):
            parts = message[4:].strip().split(maxsplit=2)
            if len(parts) >= 2:
                keyword = parts[0]
                response = parts[1]
                success, msg = await self.keyword_manager.add_keyword(
                    group_id, user_id, keyword, response, 1
                )
                await event.send(event.plain_result(msg))
                return True

        # æ¨¡ç³Šé—®ç­”
        elif message.startswith("æ¨¡ç³Šé—®ç­” "):
            parts = message[4:].strip().split(maxsplit=2)
            if len(parts) >= 2:
                keyword = parts[0]
                response = parts[1]
                success, msg = await self.keyword_manager.add_keyword(
                    group_id, user_id, keyword, response, 0
                )
                await event.send(event.plain_result(msg))
                return True

        # åŠ é€‰é¡¹
        elif message.startswith("åŠ é€‰é¡¹ "):
            parts = message[3:].strip().split(maxsplit=2)
            if len(parts) >= 2:
                keyword = parts[0]
                response = parts[1]
                success, msg = await self.keyword_manager.add_response(
                    group_id, user_id, keyword, response
                )
                await event.send(event.plain_result(msg))
                return True

        # åˆ è¯
        elif message.startswith("åˆ è¯ "):
            keyword = message[2:].strip()
            if keyword:
                success, msg = await self.keyword_manager.remove_keyword(
                    group_id, user_id, keyword
                )
                await event.send(event.plain_result(msg))
                return True

        # æŸ¥è¯
        elif message.startswith("æŸ¥è¯ "):
            keyword = message[2:].strip()
            keywords = await self.keyword_manager.list_keywords(
                group_id, user_id, keyword
            )

            if keywords:
                result = "å…³é”®è¯åˆ—è¡¨ï¼š\n" + "\n".join(keywords[:20])
                if len(keywords) > 20:
                    result += f"\n...è¿˜æœ‰ {len(keywords)-20} ä¸ªè¯æ¡"
            else:
                result = "æœªæ‰¾åˆ°ç›¸å…³å…³é”®è¯"

            await event.send(event.plain_result(result))
            return True

        # è¯åº“æ¸…ç©ºï¼ˆç§èŠä½¿ç”¨ï¼‰
        elif message == "è¯åº“æ¸…ç©º":
            lexicon_id = self.keyword_manager.get_lexicon_id(group_id, user_id)
            await self.keyword_manager.save_lexicon(lexicon_id, {"work": []})
            await event.send(event.plain_result("è¯åº“å·²æ¸…ç©º"))
            return True

        # è¯åº“å¤‡ä»½
        elif message == "è¯åº“å¤‡ä»½":
            lexicon_id = self.keyword_manager.get_lexicon_id(group_id, user_id)
            lexicon_path = StarTools.get_data_dir() / "lexicon" / f"{lexicon_id}.json"
            
            if await aos.path.exists(lexicon_path):
                backup_dir = StarTools.get_data_dir() / "backups"
                await aos.makedirs(backup_dir, exist_ok=True)
                
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                backup_path = backup_dir / f"{lexicon_id}_{timestamp}.json"
                
                try:
                    async with aiofiles.open(lexicon_path, 'r', encoding='utf-8') as src:
                        async with aiofiles.open(backup_path, 'w', encoding='utf-8') as dst:
                            await dst.write(await src.read())
                    
                    await event.send(event.plain_result(f"è¯åº“å¤‡ä»½æˆåŠŸï¼š{backup_path.name}"))
                except Exception as e:
                    logger.error(f"å¤‡ä»½è¯åº“å¤±è´¥: {e}")
                    await event.send(event.plain_result("å¤‡ä»½å¤±è´¥ï¼Œè¯·æŸ¥çœ‹æ—¥å¿—"))
            else:
                await event.send(event.plain_result("è¯åº“æ–‡ä»¶ä¸å­˜åœ¨"))
            return True

        # åˆ‡æ¢è¯åº“
        elif message.startswith("åˆ‡æ¢è¯åº“ "):
            lexicon_name = message[5:].strip()
            if lexicon_name:
                self.keyword_manager.select_config[user_id] = lexicon_name
                select_path = StarTools.get_data_dir() / "select.txt"
                lines = [f"{k}={v}" for k, v in self.keyword_manager.select_config.items()]
                try:
                    async with aiofiles.open(select_path, 'w', encoding='utf-8') as f:
                        await f.write('\n'.join(lines))
                    await event.send(event.plain_result(f"å·²åˆ‡æ¢åˆ°è¯åº“: {lexicon_name}"))
                except Exception as e:
                    logger.error(f"ä¿å­˜é€‰æ‹©é…ç½®å¤±è´¥: {e}")
                    await event.send(event.plain_result("åˆ‡æ¢å¤±è´¥ï¼Œè¯·æŸ¥çœ‹æ—¥å¿—"))
            return True

        return False

    @filter.command("keyword", alias={"å…³é”®è¯", "è¯åº“"})
    async def keyword_command(self, event: AstrMessageEvent):
        yield event.plain_result(
            "Vanè¯åº“ç³»ç»Ÿ v1.0\n\n"
            "å¯ç”¨æŒ‡ä»¤ï¼š\n"
            "1. /keyword help - æŸ¥çœ‹å¸®åŠ©\n"
            "2. /keyword list - åˆ—å‡ºå…³é”®è¯\n"
            "3. /keyword add - æ·»åŠ å…³é”®è¯\n"
            "4. /keyword delete - åˆ é™¤å…³é”®è¯\n"
            "5. /keyword search - æœç´¢å…³é”®è¯\n"
            "6. /keyword backup - å¤‡ä»½å½“å‰è¯åº“"
        )

    @filter.command("keyword help")
    async def keyword_help(self, event: AstrMessageEvent):
        help_text = """ğŸ“š Vanè¯åº“ç³»ç»Ÿä½¿ç”¨è¯´æ˜

ğŸ”§ ç®¡ç†å‘˜æŒ‡ä»¤ï¼ˆç§èŠæˆ–ç¾¤èŠä¸­ï¼‰ï¼š
1. ç²¾å‡†é—®ç­” å…³é”®è¯ å›å¤å†…å®¹
2. æ¨¡ç³Šé—®ç­” å…³é”®è¯ å›å¤å†…å®¹
3. åŠ é€‰é¡¹ å…³é”®è¯ æ–°å›å¤
4. åˆ è¯ å…³é”®è¯
5. æŸ¥è¯ å…³é”®è¯
6. åˆ‡æ¢è¯åº“ è¯åº“å
7. è¯åº“æ¸…ç©ºï¼ˆç§èŠï¼‰
8. è¯åº“å¤‡ä»½

ğŸ® æ™®é€šç”¨æˆ·æŒ‡ä»¤ï¼š
1. /keyword help - æŸ¥çœ‹å¸®åŠ©
2. /keyword list - åˆ—å‡ºå…³é”®è¯
3. /keyword search <å…³é”®è¯> - æœç´¢å…³é”®è¯

ğŸ¯ å˜é‡åŠŸèƒ½ï¼š
[qq] - è§¦å‘è€…QQ
[group] - ç¾¤å·ï¼ˆç§èŠä¸ºç©ºï¼‰
[name] - æ˜µç§°
[id] - æ¶ˆæ¯ID
[n.1] - é€šé…ç¬¦å†…å®¹

ğŸ”„ å®‰å…¨è¯­æ³•ï¼š
(1-100) - éšæœºæ•°
(+1+2*3) - å®‰å…¨è®¡ç®—
(3600~) - å†·å´æ—¶é—´
{Y>10} - æ¡ä»¶åˆ¤æ–­

ğŸ“· åª’ä½“æ”¯æŒï¼š
[å›¾ç‰‡.url]
[è‰¾ç‰¹.QQå·]
[è¡¨æƒ….id]
[å›å¤]

ğŸ’¡ æç¤ºï¼šç®¡ç†å‘˜åœ¨æ’ä»¶é…ç½®ä¸­æ·»åŠ QQå·åå¯ä½¿ç”¨ç®¡ç†å‘˜æŒ‡ä»¤"""

        yield event.plain_result(help_text)

    @filter.command("keyword list")
    @filter.permission_type(filter.PermissionType.ADMIN)
    async def keyword_list(self, event: AstrMessageEvent):
        group_id = str(event.get_group_id() or "")
        user_id = str(event.get_sender_id())

        keywords = await self.keyword_manager.list_keywords(group_id, user_id)

        if keywords:
            result = "ğŸ“‹ å…³é”®è¯åˆ—è¡¨ï¼š\n" + "\n".join(keywords[:10])
            if len(keywords) > 10:
                result += f"\n...å…± {len(keywords)} ä¸ªè¯æ¡"
        else:
            result = "å½“å‰è¯åº“ä¸ºç©º"

        yield event.plain_result(result)

    @filter.command_group("keyword")
    def keyword_group(self):
        pass

    @keyword_group.command("add")
    @filter.permission_type(filter.PermissionType.ADMIN)
    async def keyword_add(self, event: AstrMessageEvent, keyword: str, response: str):
        group_id = str(event.get_group_id() or "")
        user_id = str(event.get_sender_id())

        success, msg = await self.keyword_manager.add_keyword(
            group_id, user_id, keyword, response, 0
        )

        yield event.plain_result(msg)

    @keyword_group.command("delete")
    @filter.permission_type(filter.PermissionType.ADMIN)
    async def keyword_delete(self, event: AstrMessageEvent, keyword: str):
        group_id = str(event.get_group_id() or "")
        user_id = str(event.get_sender_id())

        success, msg = await self.keyword_manager.remove_keyword(
            group_id, user_id, keyword
        )

        yield event.plain_result(msg)

    @keyword_group.command("backup")
    @filter.permission_type(filter.PermissionType.ADMIN)
    async def keyword_backup(self, event: AstrMessageEvent):
        """å¤‡ä»½å½“å‰è¯åº“"""
        group_id = str(event.get_group_id() or "")
        user_id = str(event.get_sender_id())
        lexicon_id = self.keyword_manager.get_lexicon_id(group_id, user_id)
        
        lexicon_path = StarTools.get_data_dir() / "lexicon" / f"{lexicon_id}.json"
        
        if await aos.path.exists(lexicon_path):
            backup_dir = StarTools.get_data_dir() / "backups"
            await aos.makedirs(backup_dir, exist_ok=True)
            
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            backup_path = backup_dir / f"{lexicon_id}_{timestamp}.json"
            
            try:
                async with aiofiles.open(lexicon_path, 'r', encoding='utf-8') as src:
                    async with aiofiles.open(backup_path, 'w', encoding='utf-8') as dst:
                        await dst.write(await src.read())
                
                file_size = (await aos.stat(backup_path)).st_size
                yield event.plain_result(f"âœ… å¤‡ä»½æˆåŠŸï¼\næ–‡ä»¶å: {backup_path.name}\nå¤§å°: {file_size} å­—èŠ‚")
            except Exception as e:
                logger.error(f"å¤‡ä»½è¯åº“å¤±è´¥: {e}")
                yield event.plain_result("âŒ å¤‡ä»½å¤±è´¥ï¼Œè¯·æŸ¥çœ‹æ—¥å¿—")
        else:
            yield event.plain_result("âŒ è¯åº“æ–‡ä»¶ä¸å­˜åœ¨")

    @keyword_group.command("search")
    async def keyword_search(self, event: AstrMessageEvent, keyword: str):
        """æœç´¢å…³é”®è¯"""
        group_id = str(event.get_group_id() or "")
        user_id = str(event.get_sender_id())

        keywords = await self.keyword_manager.list_keywords(group_id, user_id, keyword)

        if keywords:
            result = f"ğŸ” æœç´¢ç»“æœï¼ˆåŒ…å« '{keyword}'ï¼‰ï¼š\n" + "\n".join(keywords[:10])
            if len(keywords) > 10:
                result += f"\n...å…±æ‰¾åˆ° {len(keywords)} ä¸ªç›¸å…³è¯æ¡"
        else:
            result = f"æœªæ‰¾åˆ°åŒ…å« '{keyword}' çš„è¯æ¡"

        yield event.plain_result(result)

    async def terminate(self):
        logger.info("Vanè¯åº“æ’ä»¶æ­£åœ¨å¸è½½...")